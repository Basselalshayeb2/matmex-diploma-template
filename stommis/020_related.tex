% !TeX spellcheck = ru_RU
% !TEX root = stommis.tex

\section{Обзор}
\label{sec:relatedworks}

В разделе приведён обзор подходов и открытых решений, необходимых для понимания разработки голосового управления в медицинской ИС.
Цель обзора~--- выбрать способ локальной предварительной обработки аудиопотока, который позволит уменьшить стоимость и ресурсоёмкость распознавания речи за счёт передачи на сервер только информативных фрагментов.

\subsection{Обзор существующих решений}
\label{subsec:rw_solutions}

\textbf{Выделение участков с речью (VAD).}
Наивный способ отделения речи от «тишины» основан на пороговой обработке энергии сигнала (RMS/амплитуда) и может быть реализован прямо в браузере.
Преимущество такого подхода~--- минимальная вычислительная сложность, однако на практике он плохо работает в условиях кабинета из‑за фонового шума и непостоянной громкости голоса.
Более устойчивым решением является классический VAD из проекта WebRTC~\cite{WebRTCVAD}, использующий статистические признаки спектра; он широко применяется в VoIP и видеоконференциях и рассчитан на работу в реальном времени.

В последние годы получили распространение нейросетевые VAD‑модели, обученные на больших корпусах аудио.
К популярным открытым решениям относится \textit{Silero VAD}~\cite{SileroVAD}, обеспечивающий высокую точность и работающий на CPU.
Недостатком является необходимость серверного выполнения (Python) или интеграции через ONNX/WebAssembly, что усложняет развёртывание на клиентской стороне.

Для браузерных приложений существует специализированный класс библиотек, которые поставляют готовую ONNX‑модель и обвязку для запуска в WebAssembly.
В данной работе рассматривается библиотека \texttt{@ricky0123/vad-web}~\cite{RickyVADWebDocs}, которая позволяет запускать VAD непосредственно в браузере, используя ONNX Runtime Web~\cite{ONNXRuntimeWeb}, и предоставляет события начала/окончания речевого сегмента.

\textbf{Ключевое слово (wake word) и выделение команды.}
Для активации голосового режима распространены подходы keyword spotting (KWS): система постоянно анализирует поток и при обнаружении ключевого слова переводит интерфейс в режим приёма команды.
Реализации могут быть (a) правилами и DTW‑сопоставлением MFCC‑признаков, (b) компактными нейросетями.
Открытым решением является \textit{openWakeWord}~\cite{OpenWakeWord}, ориентированный на запуск на CPU.
Однако внедрение KWS в браузере усложняется требованиями к аудиофреймам (фиксированный размер буфера, частота дискретизации) и необходимостью стабильного источника признаков.

Альтернативный практический подход, хорошо сочетающийся с VAD, состоит в двухэтапной схеме:
(1) на клиенте выделяются короткие речевые сегменты, (2) на сервер отправляются только сегменты, потенциально содержащие ключевое слово или команду.
Ключевое слово может проверяться по текстовой транскрипции (ASR), что повышает требования к задержке, но упрощает клиент и позволяет использовать уже существующий сервер распознавания.

\textbf{Распознавание и интерпретация команд.}
Для распознавания речи в русскоязычных приложениях применяются как локальные движки (например, Vosk), так и облачные сервисы.
В проекте используется Yandex SpeechKit~\cite{YandexSpeechKit}, поскольку он обеспечивает высокое качество ASR на русском языке и имеет готовый API, уже интегрированный в серверный контур системы.
После получения текста команды возможны два подхода: (1) строгое сопоставление с шаблонами/регулярными выражениями, (2) интерпретация через LLM с последующим приведением к фиксированному формату (intent + slots).
В работе используется гибрид: ограниченный список команд задаёт допустимые действия, а LLM применяется для устойчивого сопоставления формулировок врача с интентами и параметрами.

\subsection{Обзор используемых технологий}
\label{subsec:rw_tech}

\textbf{Захват аудио в браузере.}
Для доступа к микрофону применяется API \texttt{MediaDevices.getUserMedia}~\cite{MDNGetUserMedia}, а для потоковой обработки и/или записи~--- Web Audio API~\cite{WebAudioAPI} и MediaRecorder API~\cite{MDNMediaRecorder}.
Указанные технологии доступны во всех современных браузерах и не требуют установки дополнительного ПО на рабочее место врача.

\textbf{Браузерный VAD.}
В качестве VAD‑ядра выбран \texttt{@ricky0123/vad-web}~\cite{RickyVADWebDocs}.
Данный вариант обеспечивает баланс между простотой интеграции (JS, события \texttt{onSpeechStart/onSpeechEnd}) и ресурсной эффективностью (WebAssembly + оптимизированные вычисления ONNX Runtime Web~\cite{ONNXRuntimeWeb}).
В работе используется завершение сегмента после паузы фиксированной длительности (например, 2 секунды), что соответствует требованиям к выделению команд.

\textbf{Серверная обработка и интеграция.}
Серверный контур реализован на Python (Flask) и принимает аудио сегменты как файл \texttt{multipart/form-data}.
При необходимости входной формат приводится к Ogg Opus с помощью \texttt{ffmpeg}~\cite{FFmpeg}, после чего аудио подаётся в модуль распознавания речи (Yandex SpeechKit~\cite{YandexSpeechKit}).
Далее результат передаётся в модуль интерпретации команд (правила/LLM), который возвращает структурированное действие для заполнения полей карты пациента.

\subsection{Выводы}
\label{subsec:rw_conclusions}

По результатам обзора для прототипа выбрана архитектура \emph{VAD в браузере + ASR и интерпретация на сервере}.
Она позволяет:
\begin{itemize}
    \item снизить стоимость и сетевую нагрузку за счёт отправки на сервер только речевых сегментов, релевантных командам;
    \item сохранить качество распознавания русской речи благодаря использованию готового ASR‑сервиса;
    \item минимизировать требования к рабочему месту врача, ограничившись браузером и микрофоном.
\end{itemize}
