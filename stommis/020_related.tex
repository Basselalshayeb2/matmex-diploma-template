% !TeX spellcheck = ru_RU
% !TEX root = stommis.tex

\clearpage
\section{Обзор существующих решений}
\label{sec:relatedworks}

В данном разделе приведён обзор подходов и инструментов, применимых для построения голосового управления в медицинских информационных системах.
Основной акцент сделан на практических аспектах: как выделять речевые сегменты в аудиопотоке, как запускать обработку только в нужный момент (wake word), и как преобразовывать распознанный текст в контролируемые действия внутри МИС.

\subsection{Выделение участков речи: Voice Activity Detection}

Задача детекции речевой активности (VAD) заключается в определении моментов начала и окончания речи в непрерывном аудиопотоке.
Простейший подход основан на пороговой оценке энергии сигнала (например, RMS) и может быть реализован непосредственно в браузере.
Преимущество такого решения --- минимальная вычислительная сложность.
Недостатки проявляются в реальных условиях кабинета: фоновые шумы, переменная громкость голоса и короткие паузы приводят к нестабильным границам сегментов и к росту числа ложных срабатываний.

Более устойчивый класс решений --- классический VAD, применяемый в системах связи (например, VAD из стека WebRTC) \cite{WebRTC}.
Он широко применяется в VoIP и видеоконференциях и рассчитан на работу в реальном времени.

В последние годы получили распространение нейросетевые VAD‑модели, обученные на больших корпусах аудио.
К популярным открытым решениям относится \textit{Silero VAD}~\cite{SileroVAD}, обеспечивающий высокую точность и работающий на CPU.
Недостатком является то, что типовой сценарий использования Silero VAD предполагает серверное выполнение в Python. Запуск на стороне клиента возможен, но в этом случае требуется самостоятельно собрать и поддерживать цепочку: экспорт модели в ONNX, подключение ONNX Runtime Web и WebAssembly‑ассетов, приведение частоты дискретизации, а также контроль производительности в браузере. Для дипломного прототипа это избыточно по трудозатратам по сравнению с готовым браузерным решением.

В рамках дипломной работы для браузера был выбран open-source инструмент \texttt{@ricky0123/vad-web} \cite{RickyVADWeb}, который применяет нейросетевую модель (в формате ONNX) и исполняет её через ONNX Runtime Web \cite{ONNXRuntimeWeb}.
Данный вариант обеспечивает более устойчивое выделение речи по сравнению с пороговой энергией и допускает работу «на месте» (в браузере) без постоянных серверных вычислений.


\subsection{Активация голосового режима: wake word / keyword spotting}

Чтобы врач мог использовать голосовые команды \emph{в процессе лечения} без нажатия кнопок, требуется механизм активации голосового режима по ключевому слову (wake word).
В литературе и практике встречаются два основных класса решений:
\begin{itemize}
    \item \textbf{Локальное keyword spotting (KWS):} ключевое слово детектируется на клиенте по аудиопризнакам (например, MFCC) с использованием DTW‑сопоставления или небольшой нейросети.
    \item \textbf{Серверная проверка ключевого слова через ASR:} на клиенте выделяются короткие сегменты речи (VAD), после чего на сервер отправляется короткий фрагмент для распознавания, и активация выполняется по текстовой транскрипции.
\end{itemize}

Плюсом локального KWS является минимальная задержка и отсутствие сетевых обращений в режиме ожидания.
Минусы проявляются в прикладном сценарии стоматологии: существенно меняются микрофоны/акустика, вариативны голоса, а обучение на каждого врача (персонализация) ухудшает удобство внедрения.
Среди open-source решений KWS можно отметить проект \textit{openWakeWord} \cite{OpenWakeWord}, ориентированный на CPU‑исполнение. Однако перенос KWS непосредственно в браузер требует воспроизводимой цепочки обработки аудио: ресэмплирование до фиксированной частоты (например, 16~кГц), разбиение на фреймы фиксированного размера, применение окна, вычисление спектра (FFT) и извлечение признаков (например, MFCC) с одинаковой нормализацией. На практике даже небольшие расхождения в размерах буфера/FFT или в нормализации приводят к росту доли пропусков (ложных отрицаний, false negatives) и требуют отдельной калибровки под конкретный микрофон и голос.

Серверная проверка ключевого слова через ASR проще интегрируется в существующий серверный контур распознавания речи.
Кроме того, этот подход позволяет обойти необходимость обучения на каждого врача, однако он увеличивает число обращений к ASR по сравнению с чисто локальным KWS.

В дипломной работе исследовались оба варианта (см. раздел~\ref{subsec:wakeword}): клиентский вариант был реализован как прототип, но не прошёл испытания из‑за высокой доли пропусков (false negatives) и из‑за необходимости обучения под конкретного врача; в итоговой версии используется серверная проверка ключевого слова на основе ASR.

\subsection{Распознавание речи (ASR) и выбор сервиса}

После выделения аудиосегмента система должна получить текстовую транскрипцию команды.
В практических системах используются как локальные движки распознавания (например, Vosk), так и облачные сервисы.
В данной работе выбран сервис Yandex SpeechKit \cite{YandexSpeechKit}, поскольку он предоставляет готовый API для русского языка.


\subsection{Интерпретация команд и ограничение допустимых действий}

В рамках данной работы для интерпретации команд рассматриваются облачные LLM-модели; в прототипе используется \texttt{qwen3-235b-a22b-fp8}, также исследуются альтернативы \texttt{gpt-oss-20b}. На этапе предварительного анализа также рассматривались YandexGPT и (в перспективе) DeepSeek; однако в основной конфигурации прототипа зафиксирована модель \texttt{qwen3-235b-a22b-fp8}.

Полученный текст команды необходимо преобразовать в действие внутри МИС.
Классические подходы включают грамматические правила и классификацию интентов (англ. \textit{intent}) и параметров‑слотов (англ. \textit{slots}) для фиксированного набора команд.
Однако естественная речь врача вариативна, поэтому жёсткие шаблоны быстро усложняются и требуют постоянной поддержки.

Перспективный подход --- использование языковой модели (LLM) для семантической интерпретации команды.
При этом критически важно ограничить допустимый вывод модели, чтобы исключить неконтролируемые действия.
В прикладных системах это достигается комбинацией:
\begin{itemize}
    \item строгого формата ответа (например, JSON) и серверной валидации;
    \item ограниченного справочника действий (список допустимых интентов) и параметров (слоты, значения из справочников);
    \item повторного запроса к модели при нарушении формата или при низкой уверенности.
\end{itemize}

\subsection{Обзор используемых технологий}
\label{subsec:rw_tech}

\textbf{Захват аудио в браузере.}
Для доступа к микрофону применяется API \texttt{MediaDevices.getUserMedia}~\cite{MDNGetUserMedia}, а для потоковой обработки и/или записи~--- Web Audio API~\cite{WebAudioAPI} и MediaRecorder API~\cite{MDNMediaRecorder}.
Указанные технологии доступны во всех современных браузерах и не требуют установки дополнительного ПО на рабочее место врача.

\textbf{Браузерный VAD.}
В качестве VAD‑ядра выбран \texttt{@ricky0123/vad-web}~\cite{RickyVADWebDocs}.
Данный вариант обеспечивает баланс между простотой интеграции (JS, события \texttt{onSpeechStart/onSpeechEnd}) и ресурсной эффективностью (WebAssembly + оптимизированные вычисления ONNX Runtime Web~\cite{ONNXRuntimeWeb}).
В работе используется завершение сегмента после паузы фиксированной длительности (например, 2 секунды), что соответствует требованиям к выделению команд.

\textbf{Серверная обработка и интеграция.}
Серверный контур реализован на Python (Flask) и принимает аудио сегменты как файл \texttt{multipart/form-data}.
При необходимости входной формат приводится к Ogg Opus с помощью \texttt{ffmpeg}~\cite{FFmpeg}, после чего аудио подаётся в модуль распознавания речи (Yandex SpeechKit~\cite{YandexSpeechKit}).
Затем на серверной стороне выполняется обнаружение и подтверждение ключевого слова активации (см. раздел 2.2). После подтверждения активации результат распознавания передаётся в модуль интерпретации команд (правила/LLM), который возвращает структурированное действие для заполнения полей карты пациента.

\subsection{Выводы}
\label{subsec:rw_conclusions}

По результатам обзора для прототипа выбрана архитектура \emph{VAD в браузере + ASR и интерпретация на сервере}.
Она позволяет:
\begin{itemize}
    \item снизить стоимость и сетевую нагрузку за счёт отправки на сервер только речевых сегментов;
    \item сохранить качество распознавания русской речи благодаря использованию готового ASR‑сервиса;
    \item минимизировать требования к рабочему месту врача, ограничившись браузером и микрофоном.
\end{itemize}
