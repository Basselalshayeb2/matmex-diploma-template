% !TeX spellcheck = ru_RU
% !TEX root = stommis.tex

\clearpage
\section{Описание решения}
\label{sec:solution}

В данном разделе описывается реализованный прототип подсистемы голосового управления для МИС «СТОММИС».
Решение построено как конвейер: на стороне клиента в браузере выделяются речевые сегменты и, при активации голосового режима, формируется аудиофрагмент команды; на сервере выполняются транскодирование (при необходимости), распознавание речи и интерпретация команды в контролируемое действие внутри МИС.

\subsection{Архитектура и поток данных}
\label{subsec:arch}

Поток обработки состоит из клиентской и серверной частей (рис.~\ref{fig:pipeline}).
Клиент отвечает за захват аудиопотока и предварительную обработку с минимальной вычислительной нагрузкой.
Сервер отвечает за «дорогие» операции (ASR и семантическая интерпретация), а также за интеграцию результата с МИС «СТОММИС».

\begin{figure}[t]
    \centering
    \fbox{\parbox{0.92\linewidth}{
    \textbf{Клиент (браузер):} Web Audio API $\rightarrow$ VAD $\rightarrow$ (активация) $\rightarrow$ сегмент команды $\rightarrow$ HTTP multipart/form-data (\texttt{file})\\
    \textbf{Сервер (Python):} приём \texttt{file} $\rightarrow$ (FFmpeg) $\rightarrow$ ASR (Yandex SpeechKit) $\rightarrow$ интерпретация (правила/LLM) $\rightarrow$ действие в МИС
    }}
    \caption{Конвейер обработки голосовой команды}
    \label{fig:pipeline}
\end{figure}

Ключевой принцип архитектуры~--- минимизировать «дорогие» операции распознавания речи, выполняя на клиенте лёгкую предварительную фильтрацию (VAD и логика активации).
Это снижает стоимость и сетевую нагрузку, а также уменьшает объём данных, передаваемых за пределы браузера.

\subsection{Клиентский модуль: захват аудио и VAD}
\label{subsec:task1}

Клиентская часть реализована как веб‑страница, получающая доступ к микрофону через Web Audio API \cite{WebAudio}.
Далее непрерывно выполняется детекция речевой активности (VAD) с использованием \texttt{@ricky0123/vad-web} \cite{RickyVADWeb}, исполняющего нейросетевую модель в формате ONNX через ONNX Runtime Web \cite{ONNXRuntimeWeb}.
VAD выдаёт события начала и окончания речи, а также оценку вероятности речи.
Пример событий VAD-модели:
\begin{itemize}
    \item \texttt{onSpeechStart}~--- фиксируется начало речевого сегмента;
    \item \texttt{onSpeechEnd}~--- сегмент считается завершённым после паузы (периода «тишины») заданной длительности;
    \item \texttt{onUpdate}~--- обновление вероятности речи (для визуализации и отладки).
\end{itemize}

Для завершения команды используется правило: \enquote{конец команды --- 2 секунды тишины}.
Практически это реализуется параметром ожидания «тишины» после окончания речи (например, \texttt{redemptionFrames}, эквивалентный приблизительно двум секундам).

Пороговые параметры VAD настраиваются экспериментально под условия кабинета:
\texttt{positiveSpeechThreshold} (чувствительность старта),
\texttt{negativeSpeechThreshold} (чувствительность окончания),
а также \texttt{redemptionFrames}, задающий длительность «тишины» до завершения сегмента.

\subsection{Клиентский модуль: активация и выделение команды}
\label{subsec:task2}

Основная проблема непрерывного распознавания речи состоит в том, что на сервер уходит \emph{весь} аудиопоток (включая фоновые разговоры и паузы), что приводит к росту стоимости и нагрузки.
Для решения используется двухэтапная логика:
\begin{enumerate}
    \item \textbf{Режим мониторинга:} VAD работает постоянно, но речевые сегменты не отправляются на сервер.
    \item \textbf{Режим команды:} после обнаружения ключевого слова (например, \enquote{старт}) ближайший речевой сегмент считается командой и отправляется на сервер.
\end{enumerate}

В прототипе предусмотрены два варианта активации:
\begin{itemize}
    \item \textbf{Ручная активация} (кнопка / горячая клавиша)~--- используется как контрольный сценарий и позволяет сравнить качество выделения сегмента команды;
    \item \textbf{Голосовая активация} (wake word)~--- ключевое слово определяется по коротким речевым сегментам, полученным от VAD. Практический вариант для прототипа состоит в проверке ключевого слова по текстовой транскрипции короткого сегмента на сервере (ASR), что позволяет избежать сложной KWS‑модели на клиенте.
\end{itemize}

После активации команда считается завершённой, когда VAD фиксирует паузу заданной длительности.
Получившийся сегмент команды кодируется в аудиофайл и отправляется на сервер как \texttt{multipart/form-data} с полем \texttt{file} (см.~раздел~\ref{subsec:task3}).

Клиент реализует конечный автомат состояний:

\begin{verbatim}
STATE = MONITOR
onSpeechEnd(segment):
  if STATE == MONITOR:
     maybeWakeWord(segment)   // пробуем распознать "старт"
  if STATE == ARMED:
     sendToServer(segment)    // это команда
     STATE = MONITOR

onWakeWordDetected():
  STATE = ARMED               // следующий сегмент речи считаем командой
\end{verbatim}

\subsection{Wake word: варианты реализации и выбранный подход}
\label{subsec:wakeword}

В рамках работы были реализованы и проверены два подхода.

\textbf{1) Wake word в браузере (локальный KWS).}
Прототип выполнял обнаружение ключевого слова на клиенте по аудиопризнакам (на уровне коротких сегментов, выделенных VAD).
Практические испытания показали две проблемы:
\begin{itemize}
    \item высокая доля пропусков (false negatives) в реальных условиях кабинета;
    \item необходимость обучения/калибровки под каждого врача (разные голоса и микрофоны), что неудобно для внедрения.
\end{itemize}
Поэтому данный вариант не был принят как основной.

\textbf{2) Wake word на сервере (проверка по ASR).}
В итоговой версии используется серверная проверка: короткий сегмент, выделенный VAD, распознаётся ASR, после чего выполняется текстовая проверка на наличие ключевого слова (например, \enquote{старт}).
Это увеличивает число обращений к ASR в режиме ожидания, но снижает риск пропусков и не требует обучения под каждого врача.
Фактически режим ожидания работает как \enquote{VAD + короткие ASR‑проверки}, а после успешной активации следующий сегмент речи рассматривается как команда.

\subsection{Серверный модуль: приём аудио, ASR и интерпретация}
\label{subsec:task3}

Серверная часть реализована на Python (Flask) и предоставляет HTTP‑endpoint для приёма командных аудиосегментов.
Клиент отправляет запрос вида:
\begin{itemize}
    \item метод \texttt{POST};
    \item тело \texttt{FormData} c полем \texttt{file};
    \item дополнительные поля метаданных (идентификатор врача, пациента, режим команд), если требуется контекст.
\end{itemize}

На сервере выполняются шаги:
\begin{enumerate}
    \item проверка наличия поля \texttt{file} и чтение байтов аудио в память;
    \item приведение формата аудио к поддерживаемому входу ASR: если MIME‑тип отличается от ожидаемого, выполняется транскодирование в Ogg Opus через \texttt{ffmpeg} по пайпам (без записи на диск)~\cite{FFmpeg};
    \item распознавание речи посредством Yandex SpeechKit~\cite{YandexSpeechKit};
    \item интерпретация результата: преобразование текста в структурированную команду (например, \texttt{intent} + набор параметров), пригодную для заполнения полей карты пациента.
\end{enumerate}

Интерпретация реализуется гибридно: для короткого списка команд задаётся допустимый набор интентов, а для сопоставления свободных формулировок используется LLM‑модуль.
Результат возвращается клиенту в JSON и/или применяется на стороне МИС «СТОММИС».

\paragraph{Выбор и конфигурация языковой модели.}
В прототипе для семантической интерпретации команд используется большая языковая модель \texttt{qwen3-235b-a22b-fp8}, доступная через API облачной платформы (вызов через совместимый клиент OpenAI с заданным \texttt{base\_url}).
Выбор данной модели обусловлен качеством понимания русскоязычных команд и устойчивостью к вариативным формулировкам при сохранении приемлемой задержки.
Параллельно проводится исследование альтернативной модели \texttt{gpt-oss-20b}; на момент написания работы результаты сравнения являются предварительными, поэтому в основной конфигурации прототипа фиксируется модель \texttt{qwen3-235b-a22b-fp8}.

\paragraph{Ограничение допустимого вывода модели.}
Чтобы исключить неконтролируемые действия, модель получает на вход список допустимых интентов и допустимых значений параметров (коды/идентификаторы из справочников МИС «СТОММИС»), а сервер принимает ответ \emph{только} при успешной валидации JSON по схеме и принадлежности значений разрешённым множествам.

\subsection{Интеграция со МИС «СТОММИС» и особенности предметной области}
\label{subsec:stommis}

В отличие от решений, ориентированных на «протоколирование» консультации, в рассматриваемом сценарии цель~--- заполнение структурированной карты.
Это требует:
\begin{itemize}
    \item приведения распознанного текста к заранее определённым категориям (диагноз, манипуляция, зуб, рекомендация);
    \item сопоставления со справочниками (например, список процедур и заболеваний), используемыми в STOMMIS;
    \item минимизации количества действий врача в интерфейсе (особенно при работе в перчатках).
\end{itemize}

Командный режим позволяет врачу произносить короткие инструкции, которые конвертируются в конкретные изменения в карте.
Например, команда \enquote{старт, кариес на шестом верхнем справа} может быть интерпретирована как выбор диагноза \enquote{кариес} и установка соответствующего зуба в формуле.

\subsection{Нефункциональные требования: ресурсы и приватность}
\label{subsec:nfr}

Решение спроектировано с учётом ограничений клиники:
\begin{itemize}
    \item \textbf{Ресурсоэффективность:} постоянная работа VAD в браузере должна быть существенно дешевле постоянного ASR;
    \item \textbf{Минимизация трафика:} на сервер отправляются только короткие сегменты команд;
    \item \textbf{Приватность:} исключается постоянная передача полного аудио приёма на сервер; объём передаваемых данных ограничивается командными сегментами.
\end{itemize}

Перечисленные свойства проверяются экспериментально в разделе~\ref{sec:experiment}.
